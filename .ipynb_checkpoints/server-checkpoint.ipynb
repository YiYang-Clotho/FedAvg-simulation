{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ed6969",
   "metadata": {},
   "source": [
    "# Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de770af",
   "metadata": {},
   "source": [
    "## Setting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d99f6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 100\n",
    "local_epoch = 1\n",
    "num_users = 10 # number of clients\n",
    "target_test_acc = 0.99\n",
    "lrs = [0.1]\n",
    "\n",
    "C = 1\n",
    "E = 5\n",
    "B = 10 # 'all' for a single minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ecf253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 17:30:24.481349: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import socket\n",
    "import struct\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from threading import Thread\n",
    "from threading import Lock\n",
    "\n",
    "import copy\n",
    "\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import timedelta\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tqdm import tqdm\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e026b7",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca54d616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 17:30:26.296365: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    device = \"gpu\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20256a47",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab65c69a",
   "metadata": {},
   "source": [
    "A CNN with two 5x5 convolution layers (the first with 32 channels, the second with 64, each followed with 2x2 max pooling), a fully connected layer with 512 units and ReLu activation, and a final softmax output layer (1,663,370 total parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95101fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    @staticmethod\n",
    "    def build(input_shape):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=input_shape))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(filters=64, padding='same', kernel_size=(5,5), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed60a1e",
   "metadata": {},
   "source": [
    "initialize global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f4a3388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,663,370\n",
      "Trainable params: 1,663,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "  \n",
    "global_model = model.build((28,28,1))\n",
    "initial_weights = global_model.get_weights()\n",
    "\n",
    "# client_models = [model.build((28,28,1)) for _ in range(K)]\n",
    "\n",
    "# for i in range(len(client_models)):\n",
    "#   client_models[i].compile(loss=loss, \n",
    "#                       optimizer=optimizer, \n",
    "#                       metrics=metrics)\n",
    "#   client_models[i].set_weights(global_model.get_weights())\n",
    "\n",
    "global_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c7d2c",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2741eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3271172e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(\"x_train shape:\", X_train.shape)\n",
    "print(X_train.shape[0], \"train samples\")\n",
    "print(X_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08866f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batched = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(len(y_train)) # for testing on train set\n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68adaf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (X, y) in test_batched:\n",
    "#     print(y)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1386ff9e",
   "metadata": {},
   "source": [
    "## variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9b946d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "global global_weights    \n",
    "\n",
    "clientsoclist = [0]*num_users\n",
    "\n",
    "start_time = 0\n",
    "weight_count = 0\n",
    "\n",
    "global_weights = initial_weights\n",
    "# print(global_weights)\n",
    "\n",
    "# datasetsize = [0]*num_users\n",
    "weights_list = {}\n",
    "\n",
    "lock = Lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329d2aa8",
   "metadata": {},
   "source": [
    "## Socket initialization\n",
    "### Set host address and port number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf47e0c",
   "metadata": {},
   "source": [
    "### Required socket functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bdef5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = pickle.dumps(msg)\n",
    "    l_send = len(msg)\n",
    "    msg = struct.pack('>I', l_send) + msg\n",
    "    sock.sendall(msg)\n",
    "    return l_send\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    msg =  recvall(sock, msglen)\n",
    "    msg = pickle.loads(msg)\n",
    "    return msg\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85d51008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights(weights_list):\n",
    "    avg_weights = list()\n",
    "    for j in range(len(global_weights)):\n",
    "        weights = [weights_list[k][j] for k in range(num_users)]\n",
    "        layer_mean = tf.math.reduce_mean(weights, axis=0)\n",
    "        avg_weights.append(layer_mean)\n",
    "        \n",
    "    return avg_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78fdb23",
   "metadata": {},
   "source": [
    "## Receive users for aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76b5c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive(userid, num_users, conn): #thread for receive clients\n",
    "    global weight_count\n",
    "    global global_weights\n",
    "    global weights_list\n",
    "    \n",
    "    msg = {\n",
    "        'rounds': rounds,\n",
    "        'client_id': userid,\n",
    "        'local_epoch': local_epoch,\n",
    "        'weight': global_weights\n",
    "    }\n",
    "    distribute = send_msg(conn, msg)    #send global weight\n",
    "    r = recv_msg(conn)    # get weights from clients\n",
    "    with lock:\n",
    "        weights_list[userid] = r['weight']\n",
    "        weight_count += 1\n",
    "        \n",
    "        if weight_count == num_users:\n",
    "            global_weights = average_weights(weights_list)\n",
    "            weight_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246b60e7",
   "metadata": {},
   "source": [
    "## Thread define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c48a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_thread(func, num_user):\n",
    "    global clientsoclist\n",
    "    global start_time\n",
    "    \n",
    "    thrs = []\n",
    "    print(\"timer start!\")\n",
    "    start_time = time.time()    # store start time\n",
    "    for i in range(num_user):\n",
    "        conn, addr = s.accept()\n",
    "        print('Conntected with', addr)\n",
    "        # append client socket on list\n",
    "        clientsoclist[i] = conn\n",
    "        args = (i, num_user, conn)\n",
    "        thread = Thread(target=func, args=args)\n",
    "        thrs.append(thread)\n",
    "        thread.start()\n",
    "    for thread in thrs:\n",
    "        thread.join()\n",
    "    end_time = time.time()  # store end time\n",
    "    print(\"TrainingTime: {} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16a79683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.31.2.147\n"
     ]
    }
   ],
   "source": [
    "host_name = socket.gethostbyname(socket.gethostname())\n",
    "# host_name = '13.55.165.227'\n",
    "port_number = 12345\n",
    "print(host_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11ea0ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.31.2.147\n"
     ]
    }
   ],
   "source": [
    "print(host_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826c433d",
   "metadata": {},
   "source": [
    "### Open the server socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "549e34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = socket.socket()\n",
    "s.bind((host_name, port_number))\n",
    "s.listen(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9743ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0136545a",
   "metadata": {},
   "source": [
    "## Comunication overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "495b15e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "learning rate: 0.1\n",
      "timer start!\n",
      "Conntected with ('172.31.2.147', 42440)\n",
      "Conntected with ('172.31.2.147', 42446)\n",
      "Conntected with ('172.31.2.147', 48820)\n",
      "Conntected with ('172.31.2.147', 48834)\n",
      "Conntected with ('172.31.27.186', 50766)\n",
      "Conntected with ('172.31.27.186', 50768)\n",
      "Conntected with ('172.31.27.186', 54742)\n",
      "Conntected with ('172.31.27.171', 40612)\n",
      "Conntected with ('172.31.2.147', 56150)\n",
      "Conntected with ('172.31.27.171', 33480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss='categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "result_per_lr = {}\n",
    "start = time.time()\n",
    "for lr in lrs:\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    \n",
    "    print('\\nlearning rate: {}'.format(lr))\n",
    "    \n",
    "    for r in range(rounds):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        \n",
    "        run_thread(receive, num_users)\n",
    "    \n",
    "        # evaluate current round\n",
    "        start = time.time()\n",
    "        print('\\nlearning rate: {}'.format(lr))\n",
    "        global_model.set_weights(global_weights)\n",
    "        \n",
    "        # test global model on full training set\n",
    "        for (X,y) in train_batched:\n",
    "            preds = global_model.predict(X)\n",
    "            train_loss = cce(y, preds)\n",
    "            train_acc = accuracy_score(tf.argmax(preds, axis=1), tf.argmax(y, axis=1))\n",
    "            train_losses.append(train_loss.numpy())\n",
    "            train_accs.append(train_acc)\n",
    "\n",
    "        # test global model on testing set\n",
    "        for(X, y) in test_batched:\n",
    "            preds = global_model.predict(X)\n",
    "            test_loss = cce(y, preds)\n",
    "            test_acc = accuracy_score(tf.argmax(preds, axis=1), tf.argmax(y, axis=1))\n",
    "            test_losses.append(test_loss.numpy())\n",
    "            test_accs.append(test_acc)\n",
    "\n",
    "        elapsed = (time.time() - start)\n",
    "\n",
    "        print('comm_round: {}/{} | test_acc: {:.3%} | test_loss: {:.3} | train_acc: {:.3%} | train_loss: {:.3} | elapsed: {}'.format(r+1, rounds, test_acc, test_loss, train_acc, train_loss, timedelta(seconds=elapsed)))\n",
    "        print('\\n')\n",
    "        \n",
    "    result_per_lr[lr] = {\n",
    "        'train_accs' : train_accs,\n",
    "        'test_accs' : test_accs,\n",
    "        'train_losses' : train_losses,\n",
    "        'test_losses' : test_losses\n",
    "                          }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710c7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = ''\n",
    "with open(dir+'result_per_lr_{}_{}_{}_{}.pickle'.format(B,C,E, lr), 'wb') as handle:\n",
    "    pickle.dump(result_per_lr, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7507fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end_time = time.time()  # store end time\n",
    "# print(\"TrainingTime: {} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a945034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07fcab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()  # store end time\n",
    "print(\"WorkingTime: {} sec\".format(end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
