{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ed6969",
   "metadata": {},
   "source": [
    "# Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de770af",
   "metadata": {},
   "source": [
    "## Setting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99f6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 100\n",
    "num_users = 10 # number of clients\n",
    "target_test_acc = 0.99\n",
    "lrs = [0.1]\n",
    "\n",
    "C = 1\n",
    "E = 5\n",
    "B = 10 # 'all' for a single minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ecf253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import socket\n",
    "import struct\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from threading import Thread\n",
    "from threading import Lock\n",
    "\n",
    "import copy\n",
    "\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import timedelta\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tqdm import tqdm\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e026b7",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if tf.test.gpu_device_name():\n",
    "#     device = \"gpu\"\n",
    "# else:\n",
    "#     device = \"cpu\"\n",
    "\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20256a47",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab65c69a",
   "metadata": {},
   "source": [
    "A CNN with two 5x5 convolution layers (the first with 32 channels, the second with 64, each followed with 2x2 max pooling), a fully connected layer with 512 units and ReLu activation, and a final softmax output layer (1,663,370 total parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95101fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    @staticmethod\n",
    "    def build(input_shape):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=input_shape))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(filters=64, padding='same', kernel_size=(5,5), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed60a1e",
   "metadata": {},
   "source": [
    "initialize global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a3388",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "  \n",
    "global_model = model.build((28,28,1))\n",
    "initial_weights = global_model.get_weights()\n",
    "\n",
    "global_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351058de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the entire model as a SavedModel.\n",
    "# checkpoint_path = \"training/cp.ckpt\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# # Create a callback that saves the model's weights\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)\n",
    "\n",
    "global_model.save('saved_model/global_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c7d2c",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2741eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(\"x_train shape:\", X_train.shape)\n",
    "print(X_train.shape[0], \"train samples\")\n",
    "print(X_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08866f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batched = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(len(y_train)) # for testing on train set\n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1386ff9e",
   "metadata": {},
   "source": [
    "## variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b946d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "global global_weights    \n",
    "\n",
    "clientsoclist = [0]*num_users\n",
    "\n",
    "start_time = 0\n",
    "weight_count = 0\n",
    "\n",
    "global_weights = initial_weights\n",
    "weights_list = {}\n",
    "\n",
    "lock = Lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329d2aa8",
   "metadata": {},
   "source": [
    "## Socket initialization\n",
    "### Set host address and port number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf47e0c",
   "metadata": {},
   "source": [
    "### Required socket functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdef5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = pickle.dumps(msg)\n",
    "    l_send = len(msg)\n",
    "    msg = struct.pack('>I', l_send) + msg\n",
    "    sock.sendall(msg)\n",
    "    return l_send\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    msg =  recvall(sock, msglen)\n",
    "    msg = pickle.loads(msg)\n",
    "    return msg\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d51008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights(weights_list):\n",
    "    avg_weights = list()\n",
    "    for j in range(len(global_weights)):\n",
    "        weights = [weights_list[k][j] for k in range(num_users)]\n",
    "        layer_mean = tf.math.reduce_mean(weights, axis=0)\n",
    "        avg_weights.append(layer_mean)\n",
    "        \n",
    "    return avg_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78fdb23",
   "metadata": {},
   "source": [
    "## Receive users for aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b5c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive(userid, r, num_users, conn): #thread for receive clients\n",
    "    global weight_count\n",
    "    global global_weights\n",
    "    global weights_list\n",
    "    \n",
    "    msg = {\n",
    "        'current_round': r,\n",
    "        'rounds': rounds,\n",
    "        'client_id': userid,\n",
    "        'weight': global_weights\n",
    "    }\n",
    "    distribute = send_msg(conn, msg)    #send global weight\n",
    "    receive = recv_msg(conn)    # get weights from clients\n",
    "    with lock:\n",
    "        weights_list[userid] = receive['weight']\n",
    "        if receive['current_round'] == r:\n",
    "            weight_count += 1\n",
    "        \n",
    "        if weight_count == num_users:\n",
    "            global_weights = average_weights(weights_list)\n",
    "            weight_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246b60e7",
   "metadata": {},
   "source": [
    "## Thread define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c48a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_thread(func, num_user, r):\n",
    "    global clientsoclist\n",
    "    global start_time\n",
    "    \n",
    "    thrs = []\n",
    "    print(\"timer start!\")\n",
    "    start_time = time.time()    # store start time\n",
    "    for i in range(num_user):\n",
    "        conn, addr = s.accept()\n",
    "        print('Conntected with', addr)\n",
    "        # append client socket on list\n",
    "        clientsoclist[i] = conn\n",
    "        args = (i, r, num_user, conn)\n",
    "        thread = Thread(target=func, args=args)\n",
    "        thrs.append(thread)\n",
    "        thread.start()\n",
    "    for thread in thrs:\n",
    "        thread.join()\n",
    "    end_time = time.time()  # store end time\n",
    "    print(\"TrainingTime: {} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a79683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "host_name = socket.gethostbyname(socket.gethostname())\n",
    "# host_name = '172.31.2.147'\n",
    "port_number = 12345\n",
    "print(host_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02bf287",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(host_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826c433d",
   "metadata": {},
   "source": [
    "### Open the server socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = socket.socket()\n",
    "s.bind((host_name, port_number))\n",
    "s.listen(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0136545a",
   "metadata": {},
   "source": [
    "## Comunication overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495b15e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss='categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "result_per_lr = {}\n",
    "start = time.time()\n",
    "\n",
    "dir = ''\n",
    "    \n",
    "for lr in lrs:\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    \n",
    "    print('\\nlearning rate: {}'.format(lr))\n",
    "    \n",
    "    for r in range(rounds):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        \n",
    "        run_thread(receive, num_users, r)\n",
    "    \n",
    "        # evaluate current round\n",
    "        start = time.time()\n",
    "        global_model.set_weights(global_weights)\n",
    "        \n",
    "        # test global model on full training set\n",
    "        for (X,y) in train_batched:\n",
    "            preds = global_model.predict(X)\n",
    "            train_loss = cce(y, preds)\n",
    "            train_acc = accuracy_score(tf.argmax(preds, axis=1), tf.argmax(y, axis=1))\n",
    "            train_losses.append(train_loss.numpy())\n",
    "            train_accs.append(train_acc)\n",
    "\n",
    "        # test global model on testing set\n",
    "        for(X, y) in test_batched:\n",
    "            preds = global_model.predict(X)\n",
    "            test_loss = cce(y, preds)\n",
    "            test_acc = accuracy_score(tf.argmax(preds, axis=1), tf.argmax(y, axis=1))\n",
    "            test_losses.append(test_loss.numpy())\n",
    "            test_accs.append(test_acc)\n",
    "\n",
    "        elapsed = (time.time() - start)\n",
    "\n",
    "        print('comm_round: {}/{} | test_acc: {:.3%} | test_loss: {:.3} | train_acc: {:.3%} | train_loss: {:.3} | elapsed: {}'.format(r+1, rounds, test_acc, test_loss, train_acc, train_loss, timedelta(seconds=elapsed)))\n",
    "        print('\\n')\n",
    "        global_model.save('saved_model/global_model')\n",
    "        \n",
    "    result_per_lr[lr] = {\n",
    "        'train_accs' : train_accs,\n",
    "        'test_accs' : test_accs,\n",
    "        'train_losses' : train_losses,\n",
    "        'test_losses' : test_losses\n",
    "                          }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710c7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir+'result_per_lr_{}_{}_{}_{}.pickle'.format(B,C,E, lr), 'wb') as handle:\n",
    "    pickle.dump(result_per_lr, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815fcd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plotted_metrics(result_per_lr, c_rounds):\n",
    "    plotted_train_accs= []\n",
    "    plotted_test_accs = []\n",
    "    plotted_train_losses = []\n",
    "    plotted_test_losses = []\n",
    "\n",
    "    for c in range(c_rounds):\n",
    "        best_train_acc = 0\n",
    "        best_test_acc = 0\n",
    "        best_train_loss = math.inf\n",
    "        best_test_loss = math.inf\n",
    "        for lr in result_per_lr.keys():\n",
    "            best_train_acc = max(best_train_acc, result_per_lr[lr]['train_accs'][c])\n",
    "            best_test_acc = max(best_test_acc, result_per_lr[lr]['test_accs'][c])\n",
    "            best_train_loss = min(best_train_loss, result_per_lr[lr]['train_losses'][c])\n",
    "            best_test_loss = min(best_test_loss, result_per_lr[lr]['test_losses'][c])\n",
    "\n",
    "    if c == 0:\n",
    "        plotted_train_accs.append(best_train_acc)\n",
    "        plotted_test_accs.append(best_test_acc)\n",
    "        plotted_train_losses.append(best_train_loss)\n",
    "        plotted_test_losses.append(best_test_loss)\n",
    "    else:\n",
    "        if plotted_train_accs[-1] > best_train_acc:\n",
    "            plotted_train_accs.append(plotted_train_accs[-1])\n",
    "        else:\n",
    "            plotted_train_accs.append(best_train_acc)\n",
    "\n",
    "        if plotted_test_accs[-1] > best_test_acc:\n",
    "            plotted_test_accs.append(plotted_test_accs[-1])\n",
    "        else:\n",
    "            plotted_test_accs.append(best_test_acc)\n",
    "\n",
    "        if plotted_train_losses[-1] < best_train_loss:\n",
    "            plotted_train_losses.append(plotted_train_losses[-1])\n",
    "        else:\n",
    "            plotted_train_losses.append(best_train_loss)\n",
    "\n",
    "        if plotted_test_losses[-1] < best_test_loss:\n",
    "            plotted_test_losses.append(plotted_test_losses[-1])\n",
    "        else:\n",
    "            plotted_test_losses.append(best_test_loss)\n",
    "    \n",
    "    return plotted_train_accs, plotted_test_accs, plotted_train_losses, plotted_test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3938802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotted_train_accs, plotted_test_accs, plotted_train_losses, plotted_test_losses = get_plotted_metrics(result_per_lr, c_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(1, len(plotted_train_accs)+1), plotted_train_accs, label='train')\n",
    "ax.plot(range(1,len(plotted_test_accs)+1), plotted_test_accs, label='test')\n",
    "ax.set_xticks(np.arange(0, len(plotted_test_accs)+1, 100))\n",
    "ax.axhline(y=target_test_acc, color='grey', linestyle='-', linewidth=0.5)\n",
    "ax.set_ylabel('accuracy')\n",
    "\n",
    "ax.set_xlabel('communication rounds')\n",
    "ax.set_title('B={}, C={}, E={}, Model={}, Data={}'.format(B, C, E, MODEL, DATA))\n",
    "ax.legend()\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylim(ax.get_ylim())\n",
    "ax2.set_yticks([target_test_acc])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_round_at_target = None\n",
    "for i,acc in enumerate(plotted_test_accs):\n",
    "    if acc>=target_test_acc:\n",
    "        print(\"the number of rounds to achieve target test-accuracy: \")\n",
    "        n_round_at_target = i+1\n",
    "        print(n_round_at_target)\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb111f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_at_target = None\n",
    "for i,loss in enumerate(plotted_test_losses):\n",
    "    if n_round_at_target and i==n_round_at_target-1:\n",
    "        print(\"loss at target test-accuracy: \")\n",
    "        loss_at_target = loss\n",
    "        print(loss_at_target)\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7507fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end_time = time.time()  # store end time\n",
    "# print(\"TrainingTime: {} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a945034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07fcab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()  # store end time\n",
    "print(\"WorkingTime: {} sec\".format(end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
