{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d03d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = 1\n",
    "rounds = 3\n",
    "C = 1\n",
    "E = 5\n",
    "B = 10 # 'all' for a single minibatch\n",
    "\n",
    "# rounds = 10 # default\n",
    "local_epochs = 1 # default\n",
    "lr = 0.1\n",
    "\n",
    "\n",
    "client_order = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a725e860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 17:39:13.764515: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import timedelta\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tqdm import tqdm\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "import h5py\n",
    "import socket\n",
    "import struct\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c65c908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client_order = int(input(\"client_order(start from 0): \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da85be62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_traindata = 6000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c36b7b",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818df36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39a19991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noniid_partition(y_train):\n",
    "    \"\"\"\n",
    "    sort the data by digit label, divide it into 20 shards of size 3000, and assign each of 10 clients 2 shards.\n",
    "    \"\"\"\n",
    "    n_shards = 20\n",
    "    n_per_shard = 3000\n",
    "    \n",
    "    indexes_per_client = {}\n",
    "    indexes = y_train.argsort()\n",
    "    \n",
    "    indexes_shard = np.arange(0, n_shards)\n",
    "    \n",
    "    start_idx_shard_1 = indexes_shard[client_order]*n_per_shard\n",
    "    start_idx_shard_2 = indexes_shard[n_shards - (client_order+1)]*n_per_shard\n",
    "    indexes_per_client[client_order] = np.concatenate((indexes[start_idx_shard_1:start_idx_shard_1+n_per_shard],\n",
    "                                                       indexes[start_idx_shard_2:start_idx_shard_2+n_per_shard]))\n",
    "    print(start_idx_shard_1, start_idx_shard_1+n_per_shard, start_idx_shard_2,start_idx_shard_2+n_per_shard)\n",
    "    \n",
    "    return indexes_per_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b87bd324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 12000 48000 51000\n"
     ]
    }
   ],
   "source": [
    "indexes_per_client = noniid_partition(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2c4ebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: array([25606, 12632, 18918, ..., 44433, 44436, 44437])}\n"
     ]
    }
   ],
   "source": [
    "print(indexes_per_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe4b4d1",
   "metadata": {},
   "source": [
    "Normalize, Expand Dims, and Transform Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1247e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(\"x_train shape:\", X_train.shape)\n",
    "print(X_train.shape[0], \"train samples\")\n",
    "print(X_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15925a6",
   "metadata": {},
   "source": [
    "### Create Batched Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d15826c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(indexes_client, X_train, y_train, B):\n",
    "    x = []\n",
    "    y = []    \n",
    "    for i in indexes_client:\n",
    "        x.append(X_train[i])\n",
    "        y.append(y_train[i])\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(x), list(y)))\n",
    "    return dataset.shuffle(len(y)).batch(len(y_train) if B=='all' else B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "080012df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                              | 0/1 [00:00<?, ?it/s]2023-05-01 17:39:16.291548: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.83s/it]\n"
     ]
    }
   ],
   "source": [
    "client_dataset_batched = {}\n",
    "for i, indexes in tqdm(indexes_per_client.items()):\n",
    "    client_dataset_batched[i] = create_batch(indexes, X_train, y_train, B)\n",
    "\n",
    "train_batched = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(len(y_train)) # for testing on train set\n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b6c83a",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91e7ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    @staticmethod\n",
    "    def build(input_shape):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=input_shape))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(filters=64, padding='same', kernel_size=(5,5), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ccda608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,663,370\n",
      "Trainable params: 1,663,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "local_model = model.build((28,28,1))\n",
    "local_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff47a0e",
   "metadata": {},
   "source": [
    "## Socket initialization\n",
    "### Required socket functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fad5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = pickle.dumps(msg)\n",
    "    msg = struct.pack('>I', len(msg)) + msg\n",
    "    sock.sendall(msg)\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    msg =  recvall(sock, msglen)\n",
    "    msg = pickle.loads(msg)\n",
    "    return msg\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd2a052",
   "metadata": {},
   "source": [
    "### Set host address and port number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97678404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP address: 172.31.2.147\n"
     ]
    }
   ],
   "source": [
    "host_name = input(\"IP address: \")\n",
    "# host_name = '172.16.2.211'\n",
    "port_number = 12345\n",
    "max_recv = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b0b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "add446f1",
   "metadata": {},
   "source": [
    "## SET TIMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd4b6f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timmer start!\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()    # store start time\n",
    "print(\"timmer start!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6fb42",
   "metadata": {},
   "source": [
    "### Open the client socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cdbf05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = socket.socket()\n",
    "r = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26813ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss='categorical_crossentropy'\n",
    "metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96ce9adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 29s 47ms/step - loss: 0.1059 - accuracy: 0.9667\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 0.0220 - accuracy: 0.9922\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0138 - accuracy: 0.9945\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 0.0068 - accuracy: 0.9977\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 16s 26ms/step - loss: 0.0082 - accuracy: 0.9982\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0516 - accuracy: 0.9848\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0130 - accuracy: 0.9958\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0052 - accuracy: 0.9985\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0064 - accuracy: 0.9978\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.0065 - accuracy: 0.9982\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0297 - accuracy: 0.9902\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 0.0090 - accuracy: 0.9968\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 26s 42ms/step - loss: 0.0040 - accuracy: 0.9992\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 13s 21ms/step - loss: 4.0409e-04 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 19s 32ms/step - loss: 2.6359e-04 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0196 - accuracy: 0.9935\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 0.0081 - accuracy: 0.9967\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 24s 41ms/step - loss: 6.0254e-04 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 1.5916e-04 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0183 - accuracy: 0.9942\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 26s 42ms/step - loss: 0.0035 - accuracy: 0.9988\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 9.2911e-04 - accuracy: 0.9998\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 2.3683e-04 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 15s 26ms/step - loss: 1.3435e-04 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0122 - accuracy: 0.9965\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 0.0030 - accuracy: 0.9988\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 4.1614e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 1.6188e-04 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 13s 21ms/step - loss: 9.5916e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 48ms/step - loss: 0.0157 - accuracy: 0.9947\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 19s 31ms/step - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 5.2795e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 1.4075e-04 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 1.0528e-04 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 48ms/step - loss: 0.0107 - accuracy: 0.9965\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0020 - accuracy: 0.9997\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 24s 41ms/step - loss: 1.6919e-04 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 9.1660e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0125 - accuracy: 0.9958\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 19s 31ms/step - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 2.7470e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 22s 36ms/step - loss: 1.1394e-04 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 8.1724e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 15s 26ms/step - loss: 3.8094e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 9.9824e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 6.7726e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0079 - accuracy: 0.9973\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 2.6704e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 19s 32ms/step - loss: 8.6782e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 6.1675e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 48ms/step - loss: 0.0067 - accuracy: 0.9977\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 3.9055e-04 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 1.1515e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 13s 22ms/step - loss: 7.9784e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 6.4638e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0078 - accuracy: 0.9980\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 24s 39ms/step - loss: 4.2667e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 9.9522e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 7.1776e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0082 - accuracy: 0.9973\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 4.1737e-04 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 1.3528e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 6.6526e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 5.2776e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 48ms/step - loss: 0.0033 - accuracy: 0.9988\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 1.9648e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 6.8005e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 15s 26ms/step - loss: 5.1284e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 48ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 29s 49ms/step - loss: 2.9483e-04 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 6.2067e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 3.7691e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 3.1999e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0043 - accuracy: 0.9988\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 3.3020e-04 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 6.3985e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 4.3243e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 3.4974e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 48ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 3.2515e-04 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 9.5989e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 24s 39ms/step - loss: 4.5797e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 3.6227e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 0.0038 - accuracy: 0.9983\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 2.6212e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 22s 36ms/step - loss: 5.7914e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 4.0195e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0075 - accuracy: 0.9977\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 5.0387e-04 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 18s 31ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 24s 41ms/step - loss: 2.0767e-04 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 17s 29ms/step - loss: 5.3298e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 6.4285e-04 - accuracy: 0.9997\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 1.9147e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 3.3539e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 2.5744e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 8.8999e-04 - accuracy: 0.9997\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 1.3086e-04 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 4.2154e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 3.1455e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 14s 23ms/step - loss: 2.6226e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 7.7695e-05 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 4.0821e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 3.0949e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 2.6032e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 48ms/step - loss: 6.3650e-04 - accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 7.7250e-05 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 4.0133e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 3.0644e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 22s 36ms/step - loss: 2.5847e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 5.2715e-04 - accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 6.0154e-05 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 3.3657e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 2.7654e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 11s 19ms/step - loss: 2.3126e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 2.1091e-04 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 5.7112e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 24s 39ms/step - loss: 3.7185e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 13s 22ms/step - loss: 2.9355e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 4.1589e-04 - accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 5.0827e-05 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 3.4946e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 24s 39ms/step - loss: 2.7712e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 13s 21ms/step - loss: 2.3281e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0056 - accuracy: 0.9988\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 2.9781e-04 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 4.3612e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 3.0880e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 20s 33ms/step - loss: 2.5029e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 48ms/step - loss: 7.3596e-04 - accuracy: 0.9998\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 4.7619e-05 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 2.9011e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 2.2979e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 1.9570e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 48ms/step - loss: 7.9710e-04 - accuracy: 0.9998\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 5.6089e-05 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 2.9296e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 22s 36ms/step - loss: 2.3461e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 15s 26ms/step - loss: 1.9945e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 48ms/step - loss: 5.1529e-04 - accuracy: 1.0000\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 29s 48ms/step - loss: 5.0964e-05 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 3.6383e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 21s 34ms/step - loss: 2.8778e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 20s 33ms/step - loss: 2.4015e-05 - accuracy: 1.0000\n",
      "Local training finished\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 30s 48ms/step - loss: 5.6057e-04 - accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 19s 31ms/step - loss: 4.2166e-05 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 3.1200e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "348/600 [================>.............] - ETA: 11s - loss: 3.0511e-05 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "# update weights from server\n",
    "# train\n",
    "\n",
    "# s.connect((host_name, port_number))\n",
    "while r < rounds:\n",
    "    s = socket.socket()\n",
    "    s.connect((host_name, port_number))\n",
    "    msg = recv_msg(s)\n",
    "    rounds = msg['rounds'] \n",
    "    client_id = msg['client_id']\n",
    "    local_epochs = msg['local_epoch']\n",
    "    global_weights = msg['weight']\n",
    "    local_model.set_weights(global_weights)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr)\n",
    "    local_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    #     history = local_model.fit(client_dataset_batched[client_order], epochs=E, verbose=1)\n",
    "    local_model.fit(client_dataset_batched[client_order], epochs=E, verbose=1)\n",
    "    print('Local training finished')\n",
    "    #     evaluate = local_model.evaluate(test_batched)\n",
    "\n",
    "    weight = local_model.get_weights()\n",
    "    reply = {\n",
    "        'rounds': rounds,\n",
    "        'client_id': client_id,\n",
    "        'local_epoch': local_epochs,\n",
    "        'weight': weight\n",
    "    }\n",
    "    send_msg(s, reply)\n",
    "    \n",
    "    r += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d8839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d209ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()  #store end time\n",
    "print(\"Training Time: {} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee3ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
